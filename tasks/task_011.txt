# Task ID: 11
# Title: Observability Stack Implementation
# Status: pending
# Dependencies: 2, 5, 7, 10
# Priority: medium
# Description: Set up Prometheus metrics, Loki logs, and Grafana dashboards for monitoring the system's performance and health.
# Details:
1. Add Prometheus metrics to each service:
```python
from prometheus_client import Counter, Histogram, start_http_server

# Metrics
issue_counter = Counter('issues_processed_total', 'Total number of issues processed', ['status'])
processing_time = Histogram('issue_processing_seconds', 'Time spent processing issues')

# Start metrics server
start_http_server(8000)
```
2. Configure Loki for log aggregation:
   - Add logging configuration to each service
   - Ship logs to Loki using Promtail
3. Create Grafana dashboards:
   - System overview (service health, throughput)
   - Performance metrics (latency, processing time)
   - Error rates and types
   - OpenAI API usage and costs
4. Set up alerting for critical metrics:
   - High error rates
   - Elevated latency
   - API rate limit approaching
5. Add tracing with OpenTelemetry for end-to-end request flow
6. Configure retention policies for metrics and logs

# Test Strategy:
1. Verify metrics collection from all services
2. Test log aggregation and search
3. Validate dashboard visualizations
4. Trigger test alerts to verify alerting pipeline
5. Measure overhead of observability stack
6. Test trace correlation across services
